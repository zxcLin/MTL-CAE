{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import *\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from ranger.ranger2020 import Ranger\n",
    "from torch_summary import summary\n",
    "\n",
    "# import custom libraries\n",
    "import import_ipynb\n",
    "from utils import *\n",
    "from dataset import *\n",
    "from net import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting args\n",
    "LR_CAE      = 0.003            # learning rate for CAE\n",
    "LR_MTL      = 0.003            # learning rate for MTL-CAE\n",
    "EPOCHS_CAE  = 150              # training epochs for CAE\n",
    "EPOCHS_MTL  = 50               # training epochs for MTL-CAE\n",
    "BATCH_SIZE  = 8                # batch size\n",
    "PRINT_IDX   = 10               # print result every PRINT_IDX epochs\n",
    "DEVICE      = 'cuda:0'         # device: 'cpu' or 'cuda'\n",
    "L2_REG      = 1e-4             # L2 regularization for each parameter\n",
    "NETCAE_FILE = 'NetCAE.pth'     # Pre-trained CAE model path\n",
    "TRAIN_CAE   = False            # True for re-training CAE\n",
    "K_FOLDS     = 10               # K-Fold CV\n",
    "RAND_STATE  = 23               # random seed\n",
    "LOSS_FUNC   = nn.BCELoss()     # Binary Cross Enptroy\n",
    "MODALITY    = 'multimodality'  # 'mri' or 'cdata' or 'multimodality'\n",
    "\n",
    "LOADER_ARGS = {                # args for torch DataLoader\n",
    "    'batch_size' : BATCH_SIZE,\n",
    "    'shuffle'    : True,\n",
    "    'num_workers': 4,\n",
    "    'pin_memory' : True,\n",
    "    'drop_last'  : True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runMTL(model, data, record):\n",
    "    \n",
    "    mri, cdata, target, task = data\n",
    "    mri, cdata, target = mri.to(DEVICE), cdata.to(DEVICE), target.to(DEVICE)\n",
    "    \n",
    "    t1_index = np.argwhere(task==1).reshape(-1)\n",
    "    t2_index = np.argwhere(task==2).reshape(-1)\n",
    "\n",
    "    out1, out2 = model(mri, cdata)\n",
    "        \n",
    "    out1 = out1[t1_index].reshape(-1)\n",
    "    out2 = out2[t2_index].reshape(-1)\n",
    "    target1 = target[t1_index].float()\n",
    "    target2 = target[t2_index].float()\n",
    "\n",
    "    loss1 = LOSS_FUNC(out1, target1)\n",
    "    loss2 = LOSS_FUNC(out2, target2)\n",
    "    loss = 0.5*loss1 + loss2\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        # update metrics\n",
    "        record.append(target2.cpu(), out2.cpu(), loss2.item())\n",
    "    \n",
    "    return loss\n",
    "        \n",
    "    \n",
    "def trainMTL(model, dataloader, optimizer, epoch):\n",
    "    model.train()\n",
    "    record = Record()    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = runMTL(model, data, record)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return record\n",
    "\n",
    "\n",
    "def validMTL(model, dataloader, epoch):\n",
    "    model.eval()\n",
    "    record = Record()\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            loss = runMTL(model, data, record)\n",
    "    return record\n",
    "\n",
    "\n",
    "def runCAE(model, data):         \n",
    "    mri, cdata, target, task = data\n",
    "    mri = mri.to(DEVICE)\n",
    "    recon = model(mri)\n",
    "    loss = F.binary_cross_entropy(recon, mri)\n",
    "    return loss, mri, recon\n",
    "\n",
    "\n",
    "def trainCAE(model, dataloader, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        loss, mri, recon = runCAE(model, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    total_loss /= len(dataloader)\n",
    "    if epoch % PRINT_IDX == 0:\n",
    "        time('-- Epoch {:2d}  rloss: {:6.4f}'.format(epoch,total_loss))\n",
    "        with torch.no_grad():\n",
    "            showMRIs(mri.cpu())\n",
    "            showMRIs(recon.cpu())\n",
    "    return total_loss\n",
    "\n",
    "        \n",
    "def validCAE(model, dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = next(iter(dataloader))\n",
    "        loss, mri, recon = runCAE(model, data)\n",
    "        time('- rloss: {:6.4f}'.format(loss.item()))\n",
    "        showMRIs(mri.cpu())\n",
    "        showMRIs(recon.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SDIR = '/media/mbl/HDD/Screening_PREPSD3'\n",
    "time('Building dataset...')\n",
    "dataset = DataBuilder(SDIR).build()\n",
    "cn = dataset.get('CN')\n",
    "ad = dataset.get('AD')\n",
    "smci = dataset.get('sMCI')\n",
    "pmci = dataset.get('pMCI')\n",
    "\n",
    "# random split 32 subjects as test set\n",
    "smci, test_smci = train_test_split(smci, test_size=16, random_state=RAND_STATE)\n",
    "pmci, test_pmci = train_test_split(pmci, test_size=16, random_state=RAND_STATE)\n",
    "\n",
    "# subects for train/valid and test, labels for Stratified K-Fold\n",
    "subjects = pd.concat((cn, ad, smci, pmci))\n",
    "test_subjects = pd.concat((test_smci, test_pmci))\n",
    "labels = np.array([0]*len(cn) + [1]*len(ad) + [2]*len(smci) + [3]*len(pmci))\n",
    "\n",
    "dataset.print()\n",
    "print('Total subjects:', len(subjects)+32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_set = ADNIDataset(pd.concat((subjects,test_subjects)), train=True, modality=MODALITY)\n",
    "dataloader = DataLoader(train_set, **LOADER_ARGS)\n",
    "model = NetCAE().to(DEVICE)\n",
    "\n",
    "if TRAIN_CAE and MODALITY!='cdata':\n",
    "    time('Training NetAE...')\n",
    "    optimizer = Ranger(model.parameters(), lr=LR_CAE, k=6)\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer,5,2,eta_min=1e-5)\n",
    "    mloss = 0.2\n",
    "    for epoch in range(1, EPOCHS_CAE + 1):\n",
    "        loss = trainCAE(model, dataloader, optimizer, epoch)\n",
    "        scheduler.step()\n",
    "        if loss < mloss:\n",
    "            torch.save(model.state_dict(), NETCAE_FILE)\n",
    "            time('Model saved: {:6.4f}'.format(loss))\n",
    "            mloss = loss\n",
    "            \n",
    "elif MODALITY=='cdata':\n",
    "    time('Use clinical feature only, skip loading model')\n",
    "    \n",
    "else:\n",
    "    time('NetAE Result...')\n",
    "    model.load_state_dict(torch.load(NETCAE_FILE))\n",
    "    validCAE(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=K_FOLDS, random_state=RAND_STATE, shuffle=True)\n",
    "for k, (train_index, valid_index) in enumerate(kfold.split(subjects,labels), 1):\n",
    "\n",
    "    # setting train/valid/test dataset\n",
    "    train_set = subjects.iloc[train_index]\n",
    "    valid_set = subjects.iloc[valid_index]\n",
    "    test_set  = test_subjects\n",
    "        \n",
    "    train_set = ADNIDataset(train_set, train=True,  modality=MODALITY)\n",
    "    valid_set = ADNIDataset(valid_set, train=False, modality=MODALITY)\n",
    "    test_set  = ADNIDataset(test_set,  train=False, modality=MODALITY)\n",
    "        \n",
    "    train_loader = DataLoader(train_set, **LOADER_ARGS)\n",
    "    valid_loader = DataLoader(valid_set, **LOADER_ARGS)\n",
    "    test_loader  = DataLoader(test_set,  **LOADER_ARGS)\n",
    "    \n",
    "    # loading model\n",
    "    autoencoder = NetCAE().to(DEVICE)\n",
    "    autoencoder.load_state_dict(torch.load(NETCAE_FILE))\n",
    "    autoencoder.encoder[:3].requires_grad_(False)\n",
    "        \n",
    "    model = NetMTL(autoencoder.encoder, modality=MODALITY).to(DEVICE)\n",
    "    \n",
    "    # optimizer & LR scheduler\n",
    "    optimizer = Ranger(model.parameters(), lr=LR_MTL, k=6, weight_decay=L2_REG)\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer,5,2,eta_min=1e-5)\n",
    "    \n",
    "    for epoch in range(1, EPOCHS_MTL + 1):\n",
    "        record1 = trainMTL(model, train_loader, optimizer, epoch)\n",
    "        record2 = validMTL(model, valid_loader, epoch)\n",
    "        record3 = validMTL(model, test_loader,  epoch)\n",
    "        record3.calculate()\n",
    "        print(record3.acc())\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
